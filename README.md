![](https://raw.githubusercontent.com/gabrielfernando01/AI-for-distributed-computing/master/image/ai_cover.png)

## üîß Conocimientos de AI para computo distribuido.

### üß† Fundamentos pr√°cticos:

+ Qu√© es un modelo supervisado / no supervisado.
+ Overfitting, regularizaci√≥n, validaci√≥n cruzada.
+ Evaluaci√≥n: accuracy, F1-score, ROC-AUC, etc.
+ Embeddings, vectores de caracter√≠sticas.
+ Transfer learning (usar modelos preentrenados).

***

## ‚öôÔ∏è Herramientas y frameworks clave.

### üìå Lo m√≠nimo que deber√≠as dominar:

![](https://raw.githubusercontent.com/gabrielfernando01/AI-for-distributed-computing/master/image/table_frameworks.png)

***

## ü§ñ Modelos y t√©cnicas actuales m√°s √∫tiles.

Aprende solo los m√°s aplicables a procesamiento distribuido:

+ **NLP (Procesamiento de texto)**: BERT, DistilBERT, GPT (ya empaquetados).
+ **Computer Vision**: modelos ResNet, segmentaci√≥n, clasificaci√≥n.
+ **Recomendadores**: ALS en Spark MLlib o embeddings.
+ **Modelos de series de tiempo**: Prophet, LSTM (pero puedes integrar con Spark para escalar).

Lo clave es: saber **c√≥mo aplicar modelos ya entrenados** sobre datos grandes.

***

## üîå C√≥mo conectar IA y C√≥mputo Distribuido (Scala + Spark).

Aqu√≠ una arquitectura ejemplo:

```
[1] Ingesta de datos (Kafka/S3/HDFS)
     ‚Üì
[2] Preprocesamiento distribuido (Spark + Scala)
     ‚Üì
[3] Aplicaci√≥n de modelo (Spark MLlib o llamado a modelo HF/TF exportado)
     ‚Üì
[4] Almacenamiento (S3 / Redshift / ElasticSearch)
     ‚Üì
[5] Dashboard / API / MLflow monitoring
```
***

## üé± Types of Machine Learning:

There are many types of machine learning but the most famous types are:

+ ü•ä Supervised learning.
+ üåü Unsupervised learning.
+ üî• Reinforcement learning.

### ü•ä Supervised learning.

En el aprendizaje supervisado, el algoritmo se entrena con datos etiquetados, lo que significa que los datos de entrenamiento incluyen los pares de entrada y salida. El objetivo es aprender la correspondencia entre la entrada y la salida.

```
X -> Y 
```

Some examples of supervised learning include image classification, email spam
detection, and predicting software.

**‚ö° Types of supervised learning tasks:**

1. Regression
2. Classification

**‚ôüÔ∏è Regression**:

La regresi√≥n es un tipo de tarea de aprendizaje supervisado donde el objetivo del algoritmo es predecir una salida num√©rica continua o una variable objetivo. En la regresi√≥n, la salida es un n√∫mero real, y el objetivo del algoritmo es aprender una correspondencia entre las caracter√≠sticas de entrada y esta salida continua.

Algunos ejemplos de tareas de regresi√≥n incluyen la predicci√≥n del precio de la vivienda, la predicci√≥n de la masa de un agujero negro, la predicci√≥n del precio de las acciones, la estimaci√≥n de la edad, etc.

**ü§ñ Algorithms**:

+ üç¨ **Linear Regression**:

La regresi√≥n lineal es una t√©cnica estad√≠stica y de aprendizaje autom√°tico fundamental para resolver problemas de regresi√≥n, utilizada para modelar la relaci√≥n entre una variable dependiente (u objetivo) y una o m√°s variables independientes (o caracter√≠sticas). Supone que esta relaci√≥n es aproximadamente lineal, lo que significa que los cambios en las variables independientes tienen un efecto lineal sobre la variable dependiente.

- **Simple Lineal Regression**

In simple linear regression, there is only one input feature.

```
Y = wx + b
```

Y = target variable
w = pendiente
x = input feature
b = intercept

### ‚≠ê Overfitting

El **overfitting** (o sobreajuste) en machine learning es cuando un modelo aprende **demasiado bien los datos de entrenamiento**, incluyendo el **ruido o las particularidades** que no generalizan bien a datos nuevos. En otras palabras, el modelo **memoriza** en lugar de **aprender patrones generales**, lo que lleva a un buen rendimiento en el conjunto de entrenamiento pero **mal desempe√±o en datos no vistos**.

**Ejemplo sencillo**

Imagina que est√°s entrenando un modelo para predecir precios de casas, y una de las casas tiene un precio anormalmente alto porque es de un famoso. Si el modelo se ajusta a ese dato espec√≠fico, pensar√° que todas las casas con caracter√≠sticas similares tambi√©n deben ser car√≠simas, aunque eso no sea cierto.

***

**Se√±ales de overfitting**:

+ **Baja p√©rdida/error en entrenamiento**, pero **alta p√©rdida/error en validaci√≥n/test**.
+ El modelo se vuelve muy complejo: muchas capas, muchos par√°metros, o √°rboles muy profundos (en modelos como Random Forest o XGBoost).

***

**C√≥mo evitar el overfiting**:

+ **Regularizaci√≥n**: t√©cnicas como L1 o L2.
+ **Dropout** en redes neuronales.
+ **Reducir la complejidad** del modelo.
+ **M√°s datos** de entrenamiento.
+ **Validaci√≥n cruzada** (cross-validation).
+ **Early stopping**: detener el entrenamiento cuando el error de validaci√≥n empieza a subir

***
## üõ†Ô∏è Siguiente paso recomendado.

Construir proyecto



